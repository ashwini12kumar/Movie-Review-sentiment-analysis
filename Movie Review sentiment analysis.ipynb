{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label\n",
       "0  A very, very, very slow-moving, aimless movie ...      0\n",
       "1  Not sure who was more lost - the flat characte...      0\n",
       "2  Attempting artiness with black & white and cle...      0\n",
       "3       Very little music or anything to speak of.        0\n",
       "4  The best scene in the movie was when Gerardo i...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data\n",
    "review = pd.read_csv(\"imdb_labelled.txt\", sep='\\t', names=['message','label'])\n",
    "print(review.shape)\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>362</td>\n",
       "      <td>361</td>\n",
       "      <td>Not recommended.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>386</td>\n",
       "      <td>384</td>\n",
       "      <td>Definitely worth checking out.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                              \n",
       "        count unique                               top freq\n",
       "label                                                      \n",
       "0         362    361                Not recommended.      2\n",
       "1         386    384  Definitely worth checking out.      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check if the dataset is imbalanced\n",
    "review.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a function to remove punctuations and stopwords\n",
    "# we will use both stemming & lemmetization to see which performs better, and what's the difference\n",
    "\n",
    "def data_cleaning_func(text):\n",
    "    text = text.lower()\n",
    "    text = [word for word in text if word not in string.punctuation]\n",
    "    text = ''.join(text)\n",
    "    text = [PorterStemmer().stem(word) for word in text.split(' ') if word not in stopwords.words('english')]\n",
    "#     text = [WordNetLemmatizer().lemmatize(word) for word in text.split(' ') if word not in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets test our function\n",
    "# sent = 'my name is Ashwini Kumar!! its fun learning python. how are u doing?? keeping good??'\n",
    "# data_cleaning_func(sent)\n",
    "\n",
    "# review.head()['message'].apply(data_cleaning_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        slowmov aimless movi distress drift young man  \n",
       "1      sure lost  flat charact audienc nearli half wa...\n",
       "2      attempt arti black  white clever camera angl m...\n",
       "3                              littl music anyth speak  \n",
       "4      best scene movi gerardo tri find song keep run...\n",
       "                             ...                        \n",
       "743              got bore watch jessic lang take cloth  \n",
       "744    unfortun virtu film product work lost regrett ...\n",
       "745                                     word embarrass  \n",
       "746                                         except bad  \n",
       "747                insult one intellig huge wast money  \n",
       "Name: message, Length: 748, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = review['message'].apply(data_cleaning_func)\n",
    "print(type(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's experiment with word vectorizing techniques\n",
    "\n",
    "# Bog of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer().fit(x)\n",
    "x_bow = cv.transform(x).toarray()\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "x_tfidf = tfidf.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748, 2543)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_bow.shape)\n",
    "x_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748, 2543)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_tfidf.shape)\n",
    "x_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "743    0\n",
       "744    0\n",
       "745    0\n",
       "746    0\n",
       "747    0\n",
       "Name: label, Length: 748, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = review['label']\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split our train-test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_bow_train, x_bow_test, y_train, y_test = train_test_split(x_bow,y, test_size=0.2)\n",
    "x_tfidf_train, x_tfidf_test, y_train, y_test = train_test_split(x_tfidf,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model1 = MultinomialNB().fit(x_bow_train,y_train)\n",
    "model2 = MultinomialNB().fit(x_tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(x_bow_test)\n",
    "y_pred2 = model2.predict(x_tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAG OF WORDS MODEL\n",
      "Confusion matrix: \n",
      " [[33 49]\n",
      " [39 29]]\n",
      "Accuracy:  0.41333333333333333\n",
      "f1 score:  0.3972602739726027\n",
      "\n",
      "TF-IDF MODEL\n",
      "Confusion matrix: \n",
      " [[53 29]\n",
      " [ 6 62]]\n",
      "Accuracy:  0.7666666666666667\n",
      "f1 score:  0.7798742138364779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "print('BAG OF WORDS MODEL')\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_test,y_pred1))\n",
    "print('Accuracy: ', accuracy_score(y_test,y_pred1))\n",
    "print('f1 score: ', f1_score(y_test,y_pred1))\n",
    "\n",
    "print()\n",
    "\n",
    "print('TF-IDF MODEL')\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_test,y_pred2))\n",
    "print('Accuracy: ', accuracy_score(y_test,y_pred2))\n",
    "print('f1 score: ', f1_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent 1: movie was terrible    Sentiment: Negative sentiment\n",
      "Sent 1: food was great    Sentiment: Positive Sentiment\n",
      "Sent 1: he is a good person    Sentiment: Positive Sentiment\n"
     ]
    }
   ],
   "source": [
    "# Let's take random sentences and check sentiments\n",
    "\n",
    "def sentiment_func(sent):\n",
    "    t = [data_cleaning_func(sent)]\n",
    "    t = tfidf.transform(t)\n",
    "    array = model2.predict(t)\n",
    "    \n",
    "    if array[0] == 0:\n",
    "        sentiment = 'Negative sentiment'\n",
    "    else:\n",
    "        sentiment = 'Positive Sentiment'\n",
    "    \n",
    "    print('Sent 1:', sent, '   Sentiment:', sentiment)\n",
    "\n",
    "    \n",
    "import numpy as np\n",
    "sent1 = 'movie was terrible'\n",
    "sent2 = 'food was great'\n",
    "sent3 = 'he is a good person'\n",
    "\n",
    "sentiment_func(sent1)\n",
    "sentiment_func(sent2)\n",
    "sentiment_func(sent3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- tf-Idf is givng better performance than bag of words. It is expected too, as tf-idf weights the words according to their importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
